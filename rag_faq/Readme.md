# ğŸ¤– RAG_FAQ â€“ DocumentaÃ§Ã£o TÃ©cnica

## ğŸ“‹ VisÃ£o Geral
**RAG_FAQ** Ã© um pipeline de Retrieval-Augmented Generation (RAG) que utiliza Perguntas Frequentes **(FAQs)** como estratÃ©gia de indexaÃ§Ã£o para aprimorar a recuperaÃ§Ã£o e geraÃ§Ã£o de respostas a partir de textos extensos.

O sistema gera FAQs automaticamente a partir de documentos brutos com o auxÃ­lio de um Modelo de Linguagem (LLM), converte as perguntas em vetores semÃ¢nticos por meio de **Sentence-Transformers**, realiza a busca por **similaridade de cosseno** para identificar os trechos mais relevantes e, por fim, gera respostas fundamentadas com um LLM, condicionadas ao contexto recuperado.

## ğŸ—ï¸ Arquitetura
- **GeraÃ§Ã£o de FAQs (indexaÃ§Ã£o):** `rag_faq/indexer.py` usa `langchain_openai.ChatOpenAI` com prompts para transformar textos brutos em *k* pares pergunta-resposta â†’ salvo como **`faq.csv`**.
- **Embeddings:** `rag_faq/embedder.py` codifica as strings de **pergunta** com `SentenceTransformer(model)` e salva **`embeddings.npy`** e **`faq_with_embeddings.csv`**.
- **RecuperaÃ§Ã£o:** `rag_faq/retriever.py` carrega `embeddings.npy` e calcula similaridade de cosseno (via `sklearn.metrics.pairwise.cosine_similarity`) entre a pergunta do usuÃ¡rio e os vetores das FAQs; retorna as entradas topâ€‘k de `faq.csv`.
- **GeraÃ§Ã£o:** `rag_faq/generator.py` chama um LLM com um template de prompt e o contexto recuperado para compor a resposta final.
- **CLI:** `rag_faq/main.py` orquestra **`--mode index`** (generate_faqs â†’ embed_faqs) e **`--mode query`** (RAG interativo).
- **Servidor (HTTP):** `rag_faq/server.py` expÃµe uma aplicaÃ§Ã£o Flask mÃ­nima com um formulÃ¡rio no navegador e um endpoint `/api/ask` que encapsula `generate_rag_answer`.
- **Script driver:** `run_index.py` Ã© utilizado quando o modo `--mode index` Ã© executado, demonstrando a construÃ§Ã£o de um projeto a partir de configuraÃ§Ãµes desejadas.

## ğŸ“ Estrutura de Arquivos (arquivos principais)
```
run_index.py                # Script principal para indexaÃ§Ã£o
config.yaml                 # ConfiguraÃ§Ãµes do sistema
README.md                   # DocumentaÃ§Ã£o tÃ©cnica
USAGE_GUIDE.md              # Guia de uso detalhado
notebooks/
  â”œâ”€ faq_gen.ipynb          # GeraÃ§Ã£o manual de FAQs e construÃ§Ã£o de embeddings
  â”œâ”€ load_pdf.ipynb         # PrÃ©-processamento de PDF: dividir em pÃ¡ginas/chunks e exportar CSVs
  â””â”€ rag_faq_demo.ipynb     # Demo RAG completo: construir FAQs, incorporar e consultar interativamente
prompts/
  â”œâ”€ persona_aluno.txt
  â”œâ”€ persona_pesquisador.txt
  â”œâ”€ persona_professor.txt
  â”œâ”€ response.txt
  â””â”€ rules.txt
data/
  â”œâ”€ dataset_sample.csv
  â””â”€ ppp_<curso>/           # Dados de cada curso
     â”œâ”€ ppp_<curso>.pdf
     â”œâ”€ ppp_<curso>_pages.csv
     â””â”€ ppp_<curso>_chunks.csv
projects/
  â””â”€ <projeto>/
     â”œâ”€ ppp_all_courses/    # Agregado de todos os cursos
     â”‚   â”œâ”€ individual/     # faq.csv, faq_with_embeddings.csv, embeddings.npy
     â”‚   â””â”€ unificado/      # faq.csv, faq_with_embeddings.csv, embeddings.npy
     â””â”€ ppp_<curso>/        # Pasta especÃ­fica do curso
       â”œâ”€ individual/       # faq.csv, faq_with_embeddings.csv, embeddings.npy
       â””â”€ unificado/        # faq.csv, faq_with_embeddings.csv, embeddings.npy (+ divisÃµes por persona)
rag_faq/
  â”œâ”€ main.py                # CLI (index/query)
  â”œâ”€ server.py              # Servidor Flask + /api/ask
  â”œâ”€ generator.py           # Resposta final via LLM sobre contexto recuperado
  â”œâ”€ retriever.py           # similaridade de cosseno sobre embeddings Sentence-Transformers
  â”œâ”€ indexer.py             # GeraÃ§Ã£o de FAQs baseada em LLM (CSV)
  â”œâ”€ embedder.py            # constrÃ³i embeddings.npy (+ csv com vetores)
  â”œâ”€ config.py              # load_config()
  â””â”€ utils.py               # templates de prompt e helpers de parsing JSON
```

## âš™ï¸ ConfiguraÃ§Ã£o (`config.yaml`)
A configuraÃ§Ã£o completa (segredos omitidos) usada neste repositÃ³rio Ã©:
```yaml
llm:
  faq_generator:
    provider: openrouter
    model: meta-llama/llama-4-scout
    temperature: 0.0
    api_key: ***API_KEY***

  rag_answer:
    provider: openrouter
    model: meta-llama/llama-4-scout
    temperature: 0.0
    api_key: ***API_KEY***

embedding:
  model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

retrieval:
  top_k: 5

indexing:
  questions_per_text: 10

# CONFIGURAÃ‡ÃƒO DO PIPELINE DE GERAÃ‡ÃƒO DE FAQ
pipeline:
  # Personas disponÃ­veis
  personas: ["aluno", "professor", "pesquisador"]
  
  # Fontes de dados disponÃ­veis
  data_sources:
    - name: "ppp_bcc"
      csv_file: "data/ppp_bcc/ppp_bcc_chunks.csv"
      course_name: "Bacharelado em CiÃªncia da ComputaÃ§Ã£o"
    - name: "ppp_bcd"
      csv_file: "data/ppp_bcd/ppp_bcd_chunks.csv"
      course_name: "Bacharelado em CiÃªncia de Dados"
    - name: "ppp_best"
      csv_file: "data/ppp_best/ppp_best_chunks.csv"
      course_name: "Bacharelado em EstatÃ­stica"
    - name: "ppp_bmacc"
      csv_file: "data/ppp_bmacc/ppp_bmacc_chunks.csv"
      course_name: "Bacharelado em MatemÃ¡tica Aplicada e ComputaÃ§Ã£o CientÃ­fica"
    - name: "ppp_bmat"
      csv_file: "data/ppp_bmat/ppp_bmat_chunks.csv"
      course_name: "Bacharelado em MatemÃ¡tica"
    - name: "ppp_bsi"
      csv_file: "data/ppp_bsi/ppp_bsi_chunks.csv"
      course_name: "Bacharelado em Sistemas de InformaÃ§Ã£o"
    - name: "ppp_engcomp"
      csv_file: "data/ppp_engcomp/ppp_engcomp_chunks.csv"
      course_name: "Engenharia da ComputaÃ§Ã£o"
    - name: "ppp_lce"
      csv_file: "data/ppp_lce/ppp_lce_chunks.csv"
      course_name: "Licenciatura em CiÃªncias Exatas"
    - name: "ppp_lmat"
      csv_file: "data/ppp_lmat/ppp_lmat_chunks.csv"
      course_name: "Licenciatura em MatemÃ¡tica"
    - name: "dataset_sample"
      csv_file: "data/dataset_sample.csv"
      course_name: "Sample Dataset"

paths:
  projects_dir: ./projects
  prompts_dir: ./prompts
```

**ParÃ¢metros importantes:**
- `llm.faq_generator` e `llm.rag_answer`: provider/model/temperature/api_key (use variÃ¡veis de ambiente; nÃ£o commite segredos).
- `embedding.model`: ex., `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`.
- `retrieval.top_k`: nÃºmero de FAQs para passar como contexto.
- `indexing.questions_per_text`: quantos pares Q/A por texto de entrada.
- `pipeline.personas`: personas disponÃ­veis para geraÃ§Ã£o de FAQs.
- `pipeline.data_sources`: fontes de dados configuradas com nomes, arquivos CSV e nomes dos cursos.
- `paths.projects_dir`: onde os artefatos sÃ£o criados por projeto.
- `paths.prompts_dir`: diretÃ³rio com templates de prompt usados por `utils.py`.

## ğŸ”§ Detalhes dos MÃ³dulos

### ğŸ“ `rag_faq/indexer.py`
- **FunÃ§Ã£o:** `generate_faqs(config, project_dir, texts)`
- **LLM:** `langchain_openai.ChatOpenAI` (OpenRouter) com um prompt system+user construÃ­do via `utils.load_prompt_template/format_prompt`.
- **SaÃ­da:** `project_dir / 'faq.csv'` com colunas: `source_text`, `question`, `answer`.

### ğŸ”¢ `rag_faq/embedder.py`
- **FunÃ§Ã£o:** `embed_faqs(config, project_dir)`
- **Backend:** `SentenceTransformer(config['embedding']['model'])`.
- **Entradas:** `faq.csv`.
- **SaÃ­das:** `embeddings.npy` (array NumPy alinhado com `faq.csv`) e `faq_with_embeddings.csv`.

### ğŸ” `rag_faq/retriever.py`
- **FunÃ§Ã£o:** `retrieve_similar_faqs(config, project_dir, user_question)`
- **Passos:** codificar pergunta â†’ similaridade de cosseno (`sklearn`) vs. `embeddings.npy` â†’ ranquear â†’ selecionar `top_k` de `faq.csv`.
- **Retorna:** lista com chaves `source_text`, `question`, `answer`, `score`.

### ğŸ’¬ `rag_faq/generator.py`
- **FunÃ§Ã£o:** `generate_rag_answer(config, project_dir, user_question, debug=False)`
- **Pipeline:** chama `retrieve_similar_faqs` â†’ constrÃ³i contexto â†’ solicita LLM para produzir resposta final â†’ retorna chaves `answer`, `context`, `raw_response`.

### ğŸŒ `rag_faq/server.py`
- **Flask** aplicaÃ§Ã£o de arquivo Ãºnico. Entrada CLI `start_server()` lÃª `--project` e `--config`, resolve `project_dir`, e serve:
  - `GET /` formulÃ¡rio HTML.
  - `POST /api/ask` â†’ JSON `{ question: str }` â†’ `{ answer, context }`.

### âš¡ `rag_faq/main.py`
- **CLI:** `--mode index|query`, `--project`, `--config`.
  - `index`: `generate_faqs` depois `embed_faqs`.
  - `query`: console interativo via `run_rag()`.

### ğŸš€ `run_index.py`
- MÃ³dulo principal de indexaÃ§Ã£o que implementa a lÃ³gica de geraÃ§Ã£o de FAQs e embeddings. ContÃ©m as funÃ§Ãµes `run_index()` e `run_batch_indexing()` que sÃ£o chamadas quando o modo `--mode index` Ã© executado. Suporta processamento individual (persona Ãºnica) e unificado (multi-persona), alÃ©m de processamento em lote para mÃºltiplas fontes de dados.

## ğŸ“¦ Artefatos por Projeto
- `ppp_<curso>/individual/` (Persona Ãºnica, por curso ou agregado de todos os cursos)
  - `faq.csv`
  - `faq_with_embeddings.csv` (inclui vetores)
  - `embeddings.npy`
- `ppp_<curso>/unificado/` (Multi-persona, por curso ou agregado de todos os cursos)
  - `faq.csv`
  - `faq_with_embeddings.csv` (inclui vetores)
  - `embeddings.npy`
  - `faq_aluno.csv`        # especÃ­fico da persona
  - `faq_professor.csv`    # especÃ­fico da persona
  - `faq_pesquisador.csv`  # especÃ­fico da persona
- A recuperaÃ§Ã£o Ã© similaridade de cosseno em memÃ³ria; nÃ£o Ã© necessÃ¡rio armazenamento Chroma/FAISS.

## ğŸ“¥ Como Instalar
```bash
pip install -e .
# ou
pip install .
```

> **ğŸ“– Para instruÃ§Ãµes detalhadas de uso, consulte o [USAGE_GUIDE.md](USAGE_GUIDE.md)**

