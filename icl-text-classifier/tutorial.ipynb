{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial: ICL Text Classifier\n",
        "\n",
        "This notebook shows how to use the **`icl-text-classifier`** project step by step:\n",
        "\n",
        "1. Install the package in editable mode (`pip install -e .`).\n",
        "2. Inspect the example input CSV.\n",
        "3. Create a YAML configuration file directly from the notebook (using `%%writefile`).\n",
        "4. Run the classifier from Python and inspect the results.\n",
        "\n",
        "> **Important:** Place this notebook in the **root folder** of the project (the same folder that contains `pyproject.toml`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation (editable mode)\n",
        "\n",
        "The command below installs the project in **editable mode**, so that any change in the source code\n",
        "is immediately reflected in the environment.\n",
        "\n",
        "Run it from the project root (where this notebook lives):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///home/marcacini/Documents/PROJETOS/ICL-TEXT-CLASSIFIER\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: langchain-openai>=0.1.0 in ./.venv/lib/python3.13/site-packages (from icl-text-classifier==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in ./.venv/lib/python3.13/site-packages (from icl-text-classifier==0.1.0) (2.12.5)\n",
            "Requirement already satisfied: PyYAML>=6.0 in ./.venv/lib/python3.13/site-packages (from icl-text-classifier==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: tqdm>=4.0 in ./.venv/lib/python3.13/site-packages (from icl-text-classifier==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from icl-text-classifier==0.1.0) (2.3.3)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in ./.venv/lib/python3.13/site-packages (from langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (2.8.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (0.4.49)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (25.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (0.25.0)\n",
            "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (4.11.0)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (1.0.9)\n",
            "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (0.12.0)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.0.0->icl-text-classifier==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.0.0->icl-text-classifier==0.1.0) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.0.0->icl-text-classifier==0.1.0) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (2025.11.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai>=0.1.0->icl-text-classifier==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas->icl-text-classifier==0.1.0) (2.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->icl-text-classifier==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas->icl-text-classifier==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas->icl-text-classifier==0.1.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->icl-text-classifier==0.1.0) (1.17.0)\n",
            "Building wheels for collected packages: icl-text-classifier\n",
            "  Building editable for icl-text-classifier (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for icl-text-classifier: filename=icl_text_classifier-0.1.0-0.editable-py3-none-any.whl size=4626 sha256=ee80a942194a1eb6c21ffa8b7687e2ba1f333e690a64a1fff9da81ee4a9c77f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d9k9yhro/wheels/fd/fb/1d/2c6e0b47e8c1c1cffb2caf126d7277f96770c75fc078fd0e26\n",
            "Successfully built icl-text-classifier\n",
            "Installing collected packages: icl-text-classifier\n",
            "  Attempting uninstall: icl-text-classifier\n",
            "    Found existing installation: icl-text-classifier 0.1.0\n",
            "    Uninstalling icl-text-classifier-0.1.0:\n",
            "      Successfully uninstalled icl-text-classifier-0.1.0\n",
            "Successfully installed icl-text-classifier-0.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install the package in editable (development) mode\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inspect the example input CSV\n",
        "\n",
        "The project includes an example CSV file in `examples/input.csv`. It contains a few short texts,\n",
        "each with an `ID` and a `TEXT` column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/marcacini/Documents/PROJETOS/ICL-TEXT-CLASSIFIER/examples/input.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>doc001</td>\n",
              "      <td>The city hospital has been struggling with lon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>doc002</td>\n",
              "      <td>A new primary school is being built in the out...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>doc003</td>\n",
              "      <td>Residents are worried about the recent increas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>doc004</td>\n",
              "      <td>The local government launched a mental health ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>doc005</td>\n",
              "      <td>Teachers report that the lack of updated textb...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID                                               TEXT\n",
              "0  doc001  The city hospital has been struggling with lon...\n",
              "1  doc002  A new primary school is being built in the out...\n",
              "2  doc003  Residents are worried about the recent increas...\n",
              "3  doc004  The local government launched a mental health ...\n",
              "4  doc005  Teachers report that the lack of updated textb..."
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "csv_path = Path(\"examples/input.csv\")\n",
        "print(csv_path.resolve())\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create a YAML configuration from the notebook\n",
        "\n",
        "Here we create a configuration file named `examples/config_notebook.yaml` using the notebook\n",
        "cell magic `%%writefile`.\n",
        "\n",
        "You must **edit the line with `YOUR_OPENROUTER_API_KEY` and insert your real key** before running the classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing examples/config_example.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile examples/config_example.yaml\n",
        "model:\n",
        "  name: \"mistralai/mistral-nemo\"\n",
        "  base_url: \"https://openrouter.ai/api/v1\"\n",
        "  api_key: \"YOUR_OPENROUTER_API_KEY\"  # <-- Replace with your real key\n",
        "  temperature: 0.0\n",
        "\n",
        "classification:\n",
        "  system_prompt: |\n",
        "    You are an expert classifier that assigns highly relevant classes\n",
        "    to each input text, based on public policy themes.\n",
        "\n",
        "    The predefined classes are:\n",
        "    {CLASSES_DESCRIPTION}\n",
        "\n",
        "    Rules:\n",
        "    - Only assign a class if it is clearly supported by the text.\n",
        "    - You may assign MORE THAN ONE class if they are all highly relevant.\n",
        "    - If no class is clearly relevant, return an empty list.\n",
        "    - Use only the class_id values provided.\n",
        "\n",
        "  classes:\n",
        "    - id: \"health\"\n",
        "      description: >\n",
        "        Texts about hospitals, clinics, primary care, emergency rooms,\n",
        "        doctors, nurses, vaccination campaigns, mental health support,\n",
        "        telemedicine, chronic disease monitoring, mobile clinics, and\n",
        "        other healthcare services or policies.\n",
        "\n",
        "    - id: \"education\"\n",
        "      description: >\n",
        "        Texts about schools, universities, teachers, curricula, exams,\n",
        "        remote learning platforms, tutoring, literacy programs, scholarships,\n",
        "        educational infrastructure, and teacher training.\n",
        "\n",
        "    - id: \"public_safety\"\n",
        "      description: >\n",
        "        Texts about crime, robberies, assaults, domestic violence, drug\n",
        "        trafficking, policing strategies, community policing, surveillance\n",
        "        cameras, patrols, checkpoints, and measures to improve safety in\n",
        "        public spaces or transport.\n",
        "\n",
        "    - id: \"governance\"\n",
        "      description: >\n",
        "        Texts about justice and legal systems, anti-corruption campaigns,\n",
        "        transparency, reporting misuse of public funds, and citizen oversight\n",
        "        of government actions.\n",
        "\n",
        "  csv_input_path: \"examples/input.csv\"\n",
        "  id_column: \"ID\"\n",
        "  text_column: \"TEXT\"\n",
        "\n",
        "  num_threads: 4\n",
        "  max_tries: 3\n",
        "\n",
        "  output_path: \"examples/output_classification_notebook.jsonl\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run the classifier from Python\n",
        "\n",
        "Now we import `ICLClassifier`, load the configuration we just wrote,\n",
        "run the classification, and save the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Classifying documents: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents classified: 100\n",
            "\n",
            "First 3 results:\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"doc_id\": \"doc001\",\n",
            "    \"relevant_classes\": [\n",
            "      {\n",
            "        \"class_id\": \"health\",\n",
            "        \"justification\": \"The text explicitly mentions 'city hospital', 'emergency room', 'nurses', and 'doctors', indicating healthcare services.\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"doc_id\": \"doc002\",\n",
            "    \"relevant_classes\": [\n",
            "      {\n",
            "        \"class_id\": \"education\",\n",
            "        \"justification\": \"The text explicitly mentions 'primary school', 'education', and 'access to education', making it highly relevant to the 'education' class.\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"doc_id\": \"doc003\",\n",
            "    \"relevant_classes\": [\n",
            "      {\n",
            "        \"class_id\": \"public_safety\",\n",
            "        \"justification\": \"The text explicitly mentions an increase in robberies, a public safety concern, and residents asking for more police patrols.\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from icl_classifier import ICLClassifier\n",
        "import json\n",
        "import logging\n",
        "\n",
        "logging.disable(logging.CRITICAL) # disable logging for cleaner output\n",
        "\n",
        "config_path = \"examples/config_example.yaml\"\n",
        "classifier = ICLClassifier(config_path=config_path)\n",
        "results = classifier.run()\n",
        "classifier.save_results(results)  # uses output_path from YAML\n",
        "\n",
        "print(f\"Number of documents classified: {len(results)}\")\n",
        "print(\"\\nFirst 3 results:\\n\")\n",
        "print(json.dumps(results[:3], ensure_ascii=False, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Inspect the JSONL output\n",
        "\n",
        "The results are stored in a JSONL file (one JSON object per line), at the path\n",
        "defined in `output_path` in the YAML configuration.\n",
        "\n",
        "Here we load the file and inspect the first few entries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100,\n",
              " [{'doc_id': 'doc001',\n",
              "   'relevant_classes': [{'class_id': 'health',\n",
              "     'justification': \"The text explicitly mentions 'city hospital', 'emergency room', 'nurses', and 'doctors', indicating healthcare services.\"}]},\n",
              "  {'doc_id': 'doc002',\n",
              "   'relevant_classes': [{'class_id': 'education',\n",
              "     'justification': \"The text explicitly mentions 'primary school', 'education', and 'access to education', making it highly relevant to the 'education' class.\"}]},\n",
              "  {'doc_id': 'doc003',\n",
              "   'relevant_classes': [{'class_id': 'public_safety',\n",
              "     'justification': 'The text explicitly mentions an increase in robberies, a public safety concern, and residents asking for more police patrols.'}]}])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "output_path = \"examples/output_classification_notebook.jsonl\"\n",
        "records = []\n",
        "with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        records.append(json.loads(line))\n",
        "\n",
        "len(records), records[:3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Convert to a doc × class matrix\n",
        "\n",
        "As an extra step, we can convert the JSONL results into a simple\n",
        "document × class matrix using `pandas`, with 1 indicating that the\n",
        "class was assigned to the document and 0 otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes found: ['education', 'governance', 'health', 'public_safety']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>education</th>\n",
              "      <th>governance</th>\n",
              "      <th>health</th>\n",
              "      <th>public_safety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>doc001</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>doc002</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>doc003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>doc004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>doc005</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>doc096</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>doc097</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>doc098</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>doc099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>doc100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    doc_id  education  governance  health  public_safety\n",
              "0   doc001          0           0       1              0\n",
              "1   doc002          1           0       0              0\n",
              "2   doc003          0           0       0              1\n",
              "3   doc004          0           0       1              0\n",
              "4   doc005          1           0       0              0\n",
              "..     ...        ...         ...     ...            ...\n",
              "95  doc096          0           0       1              0\n",
              "96  doc097          1           0       0              0\n",
              "97  doc098          0           1       0              1\n",
              "98  doc099          0           0       1              0\n",
              "99  doc100          0           0       0              1\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Collect all unique class_ids\n",
        "all_class_ids = set()\n",
        "for rec in records:\n",
        "    for c in rec.get(\"relevant_classes\", []):\n",
        "        all_class_ids.add(c[\"class_id\"])\n",
        "\n",
        "all_class_ids = sorted(all_class_ids)\n",
        "print(\"Classes found:\", all_class_ids)\n",
        "\n",
        "rows = []\n",
        "for rec in records:\n",
        "    row = {\"doc_id\": rec[\"doc_id\"]}\n",
        "    assigned = {c[\"class_id\"] for c in rec.get(\"relevant_classes\", [])}\n",
        "    for cid in all_class_ids:\n",
        "        row[cid] = 1 if cid in assigned else 0\n",
        "    rows.append(row)\n",
        "\n",
        "matrix_df = pd.DataFrame(rows)\n",
        "matrix_df\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
